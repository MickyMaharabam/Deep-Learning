{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPtHL5hYVB3sO428XLb7GXV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**EXPERIMENT- 6**"],"metadata":{"id":"QGUZYSiualfZ"}},{"cell_type":"code","source":["import numpy as np\n","from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder\n","\n","# Load and preprocess data\n","iris = load_iris()\n","X = iris.data\n","y = iris.target.reshape(-1, 1)\n","\n","encoder = OneHotEncoder(sparse_output=False)\n","y_encoded = encoder.fit_transform(y)\n","\n","scaler = StandardScaler()\n","X_scaled = scaler.fit_transform(X)\n","\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X_scaled, y_encoded, test_size=0.2, random_state=42\n",")\n","\n","# Activation functions and derivatives\n","def sigmoid(x): return 1 / (1 + np.exp(-x))\n","def sigmoid_deriv(x): return x * (1 - x)\n","\n","def tanh(x): return np.tanh(x)\n","def tanh_deriv(x): return 1 - x ** 2\n","\n","def relu(x): return np.maximum(0, x)\n","def relu_deriv(x): return (x > 0).astype(float)\n","\n","# ANN training function\n","def train_ann(activation):\n","    np.random.seed(42)\n","    input_size = X_train.shape[1]\n","    hidden_size = 8\n","    output_size = y_train.shape[1]\n","\n","    W1 = np.random.randn(input_size, hidden_size)\n","    b1 = np.zeros((1, hidden_size))\n","    W2 = np.random.randn(hidden_size, output_size)\n","    b2 = np.zeros((1, output_size))\n","\n","    if activation == 'sigmoid':\n","        act_fn, act_deriv = sigmoid, sigmoid_deriv\n","    elif activation == 'tanh':\n","        act_fn, act_deriv = tanh, tanh_deriv\n","    elif activation == 'relu':\n","        act_fn, act_deriv = relu, relu_deriv\n","    else:\n","        raise ValueError(\"Invalid activation function\")\n","\n","    # Training loop\n","    epochs = 1000\n","    lr = 0.01\n","    for epoch in range(epochs):\n","        # Forward pass\n","        z1 = np.dot(X_train, W1) + b1\n","        a1 = act_fn(z1)\n","        z2 = np.dot(a1, W2) + b2\n","        a2 = sigmoid(z2)\n","\n","        # Loss\n","        loss = np.mean((y_train - a2) ** 2)\n","\n","        # Backward pass\n","        d_a2 = (a2 - y_train) * sigmoid_deriv(a2)\n","        dW2 = np.dot(a1.T, d_a2)\n","        db2 = np.sum(d_a2, axis=0)\n","\n","        d_a1 = np.dot(d_a2, W2.T) * act_deriv(a1)\n","        dW1 = np.dot(X_train.T, d_a1)\n","        db1 = np.sum(d_a1, axis=0)\n","\n","        # Update weights\n","        W1 -= lr * dW1\n","        b1 -= lr * db1\n","        W2 -= lr * dW2\n","        b2 -= lr * db2\n","\n","    # Testing\n","    z1 = np.dot(X_test, W1) + b1\n","    a1 = act_fn(z1)\n","    z2 = np.dot(a1, W2) + b2\n","    a2 = sigmoid(z2)\n","\n","    accuracy = np.mean(np.argmax(a2, axis=1) == np.argmax(y_test, axis=1)) * 100\n","    print(f\"Test Accuracy using {activation.upper()}: {accuracy:.2f}%\")\n","\n","# Run for all activations\n","print(\"Running ANN for activation functions:\\n\")\n","for act in ['sigmoid', 'tanh', 'relu']:\n","    train_ann(act)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AvngqJ7zaqJh","executionInfo":{"status":"ok","timestamp":1751196025915,"user_tz":-330,"elapsed":734,"user":{"displayName":"Maharabam Micky Devi","userId":"03527759001385913701"}},"outputId":"688bbced-61b2-461c-b5fb-aa328ac518c9"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Running ANN for activation functions:\n","\n","Test Accuracy using SIGMOID: 100.00%\n","Test Accuracy using TANH: 100.00%\n","Test Accuracy using RELU: 100.00%\n"]}]},{"cell_type":"code","source":["# Load and preprocess data\n","iris = load_iris()\n","X = iris.data\n","y = iris.target.reshape(-1, 1)"],"metadata":{"id":"ihBH7wl6axUI","executionInfo":{"status":"ok","timestamp":1751196051668,"user_tz":-330,"elapsed":6,"user":{"displayName":"Maharabam Micky Devi","userId":"03527759001385913701"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"1HE_zR3vbcPg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","from sklearn.datasets import load_digits\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder\n","\n","# Load dataset\n","digits = load_digits()\n","X = digits.data  # shape: (1797, 64)\n","y = digits.target.reshape(-1, 1)\n","\n","# One-hot encode labels\n","encoder = OneHotEncoder(sparse_output=False)\n","y_encoded = encoder.fit_transform(y)\n","\n","# Scale features\n","scaler = StandardScaler()\n","X_scaled = scaler.fit_transform(X)\n","\n","# Split\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X_scaled, y_encoded, test_size=0.2, random_state=42\n",")\n","\n","# Activation functions\n","def sigmoid(x): return 1 / (1 + np.exp(-x))\n","def sigmoid_deriv(x): return x * (1 - x)\n","def tanh(x): return np.tanh(x)\n","def tanh_deriv(x): return 1 - x ** 2\n","def relu(x): return np.maximum(0, x)\n","def relu_deriv(x): return (x > 0).astype(float)\n","\n","# Train ANN\n","def train_ann(activation):\n","    np.random.seed(42)\n","    input_size = X_train.shape[1]  # 64\n","    hidden_size = 16\n","    output_size = y_train.shape[1]  # 10\n","\n","    W1 = np.random.randn(input_size, hidden_size)\n","    b1 = np.zeros((1, hidden_size))\n","    W2 = np.random.randn(hidden_size, output_size)\n","    b2 = np.zeros((1, output_size))\n","\n","    if activation == 'sigmoid':\n","        act_fn, act_deriv = sigmoid, sigmoid_deriv\n","    elif activation == 'tanh':\n","        act_fn, act_deriv = tanh, tanh_deriv\n","    elif activation == 'relu':\n","        act_fn, act_deriv = relu, relu_deriv\n","    else:\n","        raise ValueError(\"Unsupported activation function\")\n","\n","    epochs = 1000\n","    lr = 0.01\n","    for epoch in range(epochs):\n","        # Forward\n","        z1 = np.dot(X_train, W1) + b1\n","        a1 = act_fn(z1)\n","        z2 = np.dot(a1, W2) + b2\n","        a2 = sigmoid(z2)\n","\n","        # Loss\n","        loss = np.mean((y_train - a2) ** 2)\n","\n","        # Backward\n","        d_a2 = (a2 - y_train) * sigmoid_deriv(a2)\n","        dW2 = np.dot(a1.T, d_a2)\n","        db2 = np.sum(d_a2, axis=0)\n","\n","        d_a1 = np.dot(d_a2, W2.T) * act_deriv(a1)\n","        dW1 = np.dot(X_train.T, d_a1)\n","        db1 = np.sum(d_a1, axis=0)\n","\n","        # Update\n","        W1 -= lr * dW1\n","        b1 -= lr * db1\n","        W2 -= lr * dW2\n","        b2 -= lr * db2\n","\n","    # Testing\n","    z1 = np.dot(X_test, W1) + b1\n","    a1 = act_fn(z1)\n","    z2 = np.dot(a1, W2) + b2\n","    a2 = sigmoid(z2)\n","\n","    accuracy = np.mean(np.argmax(a2, axis=1) == np.argmax(y_test, axis=1)) * 100\n","    print(f\"Test Accuracy using {activation.upper()}: {accuracy:.2f}%\")\n","\n","# Run all activation functions\n","print(\"Running ANN on Digits dataset with different activations...\\n\")\n","for func in ['sigmoid', 'tanh', 'relu']:\n","    train_ann(func)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d2fanOfXaydB","executionInfo":{"status":"ok","timestamp":1751196235383,"user_tz":-330,"elapsed":8059,"user":{"displayName":"Maharabam Micky Devi","userId":"03527759001385913701"}},"outputId":"7e2c7bc6-b3b6-4ba5-fabf-1524fa379838"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Running ANN on Digits dataset with different activations...\n","\n","Test Accuracy using SIGMOID: 96.11%\n","Test Accuracy using TANH: 94.72%\n","Test Accuracy using RELU: 73.33%\n"]}]}]}